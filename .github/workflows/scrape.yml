name: Scrape FX Competitors

on:
  # Runs automatically every 15 minutes (UTC)
  schedule:
    - cron: "*/15 * * * *"
  # Allows you to trigger it manually from the Actions tab
  workflow_dispatch: {}

permissions:
  contents: read

# Prevent overlapping runs if a previous one is still going
concurrency:
  group: scrape-fx
  cancel-in-progress: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    env:
      # For date/time columns in your sheet
      TZ: Asia/Seoul
      TIMEZONE: Asia/Seoul

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: |
          if [ -f package-lock.json ]; then
            npm ci
          else
            npm install
          fi

      - name: Install Playwright Chromium
        run: npx playwright install --with-deps chromium

      - name: Show trigger
        run: echo "Event: ${{ github.event_name }}  @ ${{ github.run_started_at }}"

      - name: Run scraper
        env:
          SHEET_ID: ${{ secrets.SHEET_ID }}
          GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}
          # Optional: override tab names (otherwise index.js defaults are used)
          SHEET_VND: ${{ secrets.SHEET_VND }}
          SHEET_CNY: ${{ secrets.SHEET_CNY }}
          SHEET_NPR: ${{ secrets.SHEET_NPR }}
          SHEET_KHR: ${{ secrets.SHEET_KHR }}
        run: npm start

      # Collect screenshots/HTML when a site fails so you can inspect it
      - name: Upload debug artifacts (if any)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: debug
          path: debug/
          if-no-files-found: ignore
